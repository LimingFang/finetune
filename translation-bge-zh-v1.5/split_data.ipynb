{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import json\n",
    "import random\n",
    "\n",
    "def split_conversations(input_file, train_output_file, test_output_file):\n",
    "    data = []\n",
    "    with open(input_file) as file:\n",
    "        for item in jsonlines.Reader(file):\n",
    "            data.append(item)\n",
    "\n",
    "    num = len(data)\n",
    "    \n",
    "    random.shuffle(data)\n",
    "    random.shuffle(data)\n",
    "    random.shuffle(data)\n",
    "\n",
    "    split_point = int(num * 0.9)\n",
    "\n",
    "    train_data = data[:split_point]\n",
    "    test_data = data[split_point:]\n",
    "\n",
    "    print(f\"train data szie = {len(train_data)},train data example = {train_data[0]}\")\n",
    "    # print(f\"eval data szie = {len(eval_data)},train data example = {eval_data[0]}\")\n",
    "    print(f\"test data szie = {len(test_data)},test data example = {test_data[0]}\")\n",
    "\n",
    "    with open(train_output_file, 'w', encoding='utf-8') as f:\n",
    "        for item in train_data:\n",
    "            json_str = json.dumps(item, ensure_ascii=False)\n",
    "            f.write(json_str+\"\\n\")\n",
    "\n",
    "\n",
    "    with open(test_output_file, 'w', encoding='utf-8') as f:\n",
    "        for item in test_data:\n",
    "            json_str = json.dumps(item, ensure_ascii=False)\n",
    "            f.write(json_str+\"\\n\")\n",
    "\n",
    "    print(f\"Split complete. Train data written to {train_output_file}, Test data written to {test_output_file}\")\n",
    "\n",
    "split_conversations(\"total_minedHN.jsonl\",\"train.jsonl\",\"eval.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
